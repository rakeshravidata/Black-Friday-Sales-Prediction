# combination of x1- and x2-values, a possible           |
# realization of the process is as follows:              |
x1 <- c(seq(from=0, to=1, by=0.10), seq(from=0, to=1, by=0.10))
x2 <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
y <- c(0, 0, 0, 0, 0, 2, 2, 2, 1, 2, 2, 0, 1, 0, 0, 1, 0, 2, 2, 1, 2, 2)
# The data shown above were simulated from a logistic    |
# regression model such that                             |
#                                                        |
#             logit P[y=1] = -2.25 + 4.5 x1              |
#                                                        |
# where                                                  |
#                                                        |
#              logit p = log p - log(1-p)                |
#                                                        |
# is the logit function.                                 |
#                                                        |
# The code that produced those data is                   |
n.run <- 2
beta0 <- -2.25
beta1 <- 4.5
lin.scr <- beta0 + beta1*x1
mu <- 1 / (1 + exp(-lin.scr))
n <- rep(x=n.run, times=22)
y <- rbinom(n=length(x1), size=n, prob=mu)
# Notice that that the model specified in the algorithm  |
# that generated the data does not make any use of the   |
# "type" information coded into the variable x2. This    |
# should not prevent us from considering one that does.  |
# For instance, let us consider the model                |
#                                                        |
#      logit P[y=1] = beta0 + beta1*x1 + beta2*x2        |
#                                                        |
# Should one furthermore consider the associated         |
# hypotheses,                                            |
#                                                        |
#             H0: beta2 = 0 vs H1: beta2 ??? 0,            |
#                                                        |
# one would note that the data-generating process        |
# specified in the algorithm operates under H0.          |
#                                                        |
# Part A: Complete the task described below based on 500 |
# simulations of the data-generating process specified   |
# above.                                                 |
#                                                        |
# At each repetition of the simulation, consider the     |
# model                                                  |
#                                                        |
#      logit P[y=1] = beta0 + beta1*x1 + beta2*x2        |
#                                                        |
# and carry out a Wald test of the hypotheses            |
#                                                        |
#             H0: beta2 = 0 vs H0: beta2 ??? 0,            |
#                                                        |
# controlling for type I error at level 0.05. Then,      |
# carry out a difference-in-deviance test of the same    |
# hypotheses, again controlling for type I error at      |
# level 0.05. For each test, record whether the test     |
# rejects or fails to reject H0. In addition, record     |
# whether the tests AGREE or DISAGREE in the decision to |
# reject or fail to reject H0.                           |
set.seed(69)
alpha<-0.05
n.rep = 500
z.crit = qnorm(alpha/2,lower.tail=FALSE)
chisq.crit <- qchisq(alpha, df=1, lower.tail=FALSE)
wald = character(length = n.rep)
deviance = character(length = n.rep)
agree = character(length = n.rep)
for(rep in 1:n.rep){
y = rbinom(n=length(x1), size=n, prob=mu)
glm.full = glm(cbind(y, n-y) ~ x1 + x2, family = 'binomial')
glm.red = glm(cbind(y, n-y) ~ x1, family = 'binomial')
diff.dev = glm.red$deviance - glm.full$deviance
deviance[rep] = ifelse(diff.dev >= chisq.crit, 'Reject', "Don't reject")
b.cov.mat = summary(glm.full)$cov.scaled
s.err = sqrt(diag(b.cov.mat))
z.value = glm.full$coefficients[3]/s.err[3]
wald[rep] = ifelse(abs(z.value) > z.crit, 'Reject', "Don't reject")
agree[rep] = wald[rep] == deviance[rep]
}
table(wald)/500
#Fail to reject 95.4% of the time
table(deviance)/500
#Fail to reject 94.4% of the time
table(agree) / 500
#two methods agree 99% of the time
#                                                        |
# Once you have completed 500 simulations, calculate the |
# following relative frequencies:                        |
#                                                        |
#   (i.) the relative frequency that the Wald test       |
#        rejects H0;                                     |
#Rejects HO 4.6% of the time
#                                                        |
#  (ii.) the relative frequency that the difference-in-  |
#        deviance test rejects H0;                       |
#Rejects H0 5.6% of the time
#                                                        |
# (iii.) the relative frequency that the two tests       |
#        disagree.                                       |
#Disagree 1% of the time
#                                                        |
# Next, repeat the simulation, but this time increase    |
# the number of runs observed at each combination of x1- |
# and x2-values from two to ten:                         |
n.run <- 10
beta0 <- -2.25
beta1 <- 4.5
lin.scr <- beta0 + beta1*x1
mu <- 1 / (1 + exp(-lin.scr))
n <- rep(x=n.run, times=22)
y <- rbinom(n=length(x1), size=n, prob=mu)
set.seed(69)
alpha<-0.05
n.rep = 500
z.crit = qnorm(alpha/2,lower.tail=FALSE)
chisq.crit <- qchisq(alpha, df=1, lower.tail=FALSE)
wald = character(length = n.rep)
deviance = character(length = n.rep)
agree = character(length = n.rep)
for(rep in 1:n.rep){
y = rbinom(n=length(x1), size=n, prob=mu)
glm.full = glm(cbind(y, n-y) ~ x1 + x2, family = 'binomial')
glm.red = glm(cbind(y, n-y) ~ x1, family = 'binomial')
diff.dev = glm.red$deviance - glm.full$deviance
deviance[rep] = ifelse(diff.dev >= chisq.crit, 'Reject', "Don't reject")
b.cov.mat = summary(glm.full)$cov.scaled
s.err = sqrt(diag(b.cov.mat))
z.value = glm.full$coefficients[3]/s.err[3]
wald[rep] = ifelse(abs(z.value) > z.crit, 'Reject', "Don't reject")
agree[rep] = wald[rep] == deviance[rep]
}
table(wald)/500
#Fail to reject 94.8% of the time
table(deviance)/500
#Fail to reject 94.4% of the time
table(agree) / 500
#two methods agree 99.6% of the time
#   (i.) the relative frequency that the Wald test       |
#        rejects H0;                                     |
#Rejects HO 5.2% of the time
#                                                        |
#  (ii.) the relative frequency that the difference-in-  |
#        deviance test rejects H0;                       |
#Rejects H0 5.6% of the time
#                                                        |
# (iii.) the relative frequency that the two tests       |
#        disagree.                                       |
#Disagree 0.04% of the time
#                                                        |
# Based on what you observe in items (i), (ii), and      |
# (iii), answer and explain your answers to the          |
# following questions:                                   |
#                                                        |
#   Q1a: How accurate is the type I error of each test?  |
# To answer this question compare the simulated type I   |
# error to the stated type I error.                      |
#The stated type I error is 5% and these values are relatively closer.
#As the number of runs increases, the values become closer to 5%
#And both times, the difference in deviance was closer to 5% compared to the
#Wald test.
#                                                        |
#   Q1b: How does increasing the number of runs impact   |
# the accuracy of type I error of each test?             |
#Increasing the number of runs increases the accuracies and consistencies of the type 1 errors.
#                                                        |
#   Q2a: How well do the two tests agree in the decision |
# to reject or fail to reject H0?                        |
#They agree the vast majority of time with a maximum 1% differnce.
#                                                        |
#   Q2b: How does increasing the number of runs impact   |
# how well the two tests agree?                          |
#                                                        |
#Increasing the number of runs improves the agreement rate.
# Part B: The two tests explored in this problem, i.e.,  |
# the Wald and difference-in-deviance tests, are offered |
# by the textbook as two options for testing the         |
# significance of a single regressor in logistic         |
# regression. For example, either test may be used to    |
# test the hypotheses                                    |
#                                                        |
#             H0: beta2 = 0 vs H0: beta2 ??? 0             |
#                                                        |
# which is a test of a single regressor.                 |
#                                                        |
# Should one want to test for the significance of a      |
# subset of (more than one) regressor variables, the     |
# only option offered by the textbook is the difference- |
# in-deviance test. For instance, consider the model     |
#                                                        |
#     logit P[y=1] = beta0 + beta1*x1                    |
#                       + beta2*x2 + beta3*x1*x2         |
#                                                        |
# This model allows for differences in intercept AND     |
# slope between type=A and type=B conditions. In a test  |
# for the signficiance of the last two terms, the        |
# hypotheses are                                         |
#                                                        |
#                 H0: beta2 = beta3 = 0                  |
#                         vs                             |
#              H0: beta2 ??? 0 or beta3 ??? 0                |
#                                                        |
# The difference-in-deviance statistic would be computed |
# be comparing the devience statistic of the full model  |
#                                                        |
#     logit P[y=1] = beta0 + beta1*x1                    |
#                       + beta2*x2 + beta3*x1*x2         |
#                                                        |
# with that of the reduced model                         |
#                                                        |
#            logit P[y=1] = beta0 + beta1*x1             |
#                                                        |
## Difference in Deviance Test
## Null Hypothesis: beta2 = beta3 = 0
## Alternative Hypothesis: beta2  ??? 0 and beta3  ??? 0
# The degrees of freedom of the associated chi-square    |
# cutoff value is
df.diff.dev <- 2
alpha <- 0.05
x1 <- c(seq(from=0, to=1, by=0.10), seq(from=0, to=1, by=0.10))
x2 <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
y <- c(0, 0, 0, 0, 0, 2, 2, 2, 1, 2, 2, 0, 1, 0, 0, 1, 0, 2, 2, 1, 2, 2)
glm.full<- glm(cbind(y, n-y)  ~ x1 + x2 + x1*x2, family=binomial)
glm.reduced<- glm(cbind(y, n-y)  ~ x1 , family=binomial)
diff.dev <- glm.reduced$deviance - glm.full$deviance
# 1.047259
df.diff.dev <- 2
alpha <- 0.05
chisq.crit <- qchisq(alpha, df=df.diff.dev, lower.tail=FALSE)
chisq.crit
# [1] 5.991465
p.val <- pchisq(diff.dev, df=df.diff.dev, lower.tail=FALSE)
p.val
# [1] 0.5923667
# As p.val > 0.05 and difference in deviance is less than chi-square critical,
# We fails to reject the null hypothesis
# wald test
# H0: beta2 = beta3 = 0                                       |
# H1: beta2 ??? 0 or beta3 ??? 0
b2.hat <- summary(glm.full)$coefficients[3,1]
b3.hat <- summary(glm.full)$coefficients[4,1]
b.hat.vect <- as.matrix(c(b2.hat, b3.hat))
b.cov.mat <- summary(glm.full)$cov.scaled[3:4,3:4]
b.cov.inv <- solve(b.cov.mat)
Wald.stat <- as.numeric(t(b.hat.vect) %*% b.cov.inv %*% b.hat.vect)
Wald.stat
# 0.8861991
df.Wald <- 2
alpha <- 0.05
chisq.crit <- qchisq(alpha, df=df.diff.dev, lower.tail=FALSE)
chisq.crit
# 5.991465
p.val <- pchisq(Wald.stat, df=df.Wald, lower.tail=FALSE)
p.val
# 0.6420433
# Since pval>0.05 and Wald statistic is less than chi-square critical.
# We fail to reject the null hypothesis through the Wald Test.
library(tidyverse)
library(readr)
flights  <- read_csv ("data/flights.csv")
airports <- read_csv ("data/airports.csv")
airlines <- read_csv ("data/airlines.csv")
flights2<-flights
#removing cancelled flights
flights = flights[flights$CANCELLED == 0,]
nrow(flights)
#removing missing values in Arrival Delays
flights = flights[complete.cases(flights$ARRIVAL_DELAY), ]
nrow(flights_clean)
#remove diverted flights
flights = flights[flights$DIVERTED == 0,]
nrow(flights)
flights = flights[flights$ARRIVAL_DELAY < -60,]
nrow(flights)
flights  <- read_csv ("data/flights.csv")
airports <- read_csv ("data/airports.csv")
airlines <- read_csv ("data/airlines.csv")
flights2<-flights
#removing cancelled flights
flights = flights[flights$CANCELLED == 0,]
nrow(flights)
#removing missing values in Arrival Delays
flights = flights[complete.cases(flights$ARRIVAL_DELAY), ]
nrow(flights)
#remove diverted flights
flights = flights[flights$DIVERTED == 0,]
nrow(flights)
flights = flights[flights$ARRIVAL_DELAY > -60,]
nrow(flights)
flights %>% group_by(ORIGIN_AIRPORT)%>% summarise(no_rows=length(ORIGIN_AIRPORT))
unique(flights$ORIGIN_AIRPORT)
flights %>% group_by(ORIGIN_AIRPORT)%>% summarise(no_rows=length(ORIGIN_AIRPORT))
sum(unique(flights$ORIGIN_AIRPORT))
length(unique(flights$ORIGIN_AIRPORT))
install.packages("pacman")
install.packages("caTools")
install.packages("hydroGOF")
setwd("~/GitHub/STAT6021_42")
library(tidyverse)
library(readr)
library(leaps)
library(tidyverse)
library(readr)
library(leaps)
get.model.str <- function(var.in, resp.name, reg.names) {
var.in.idx <- which(var.in)
model.str <- paste(resp.name, "~")
first.in <- TRUE
for (iVAR in var.in.idx) {
if (first.in) {
model.str <- paste(model.str, reg.names[iVAR])
first.in <- FALSE
} else {
model.str <- paste(model.str, "+", reg.names[iVAR])
}
}
return(model.str)
}
eval.lm <- function(model.str, data.name) {
lm.call.str <- paste("reg.lm <- lm(", model.str, ", data=", data.name, ")")
eval(parse(text=lm.call.str))
return(reg.lm)
}
forward.step <- function(curr.var.in, alpha.in, resp.name, reg.names, data.name) {
curr.var.out.idx <- which(!curr.var.in)
enter.idx <- NA
if (length(curr.var.out.idx) > 0) {
k <- length(reg.names)
pval.seq <- rep(x=Inf, times=k)
for (iVAR in curr.var.out.idx) {
cand.var.in <- curr.var.in
cand.var.in[iVAR] <- TRUE
cand.model.str <- get.model.str(cand.var.in, resp.name, reg.names)
cand.model.lm <- eval.lm(cand.model.str, data.name)
iROW <- which(row.names(summary(cand.model.lm)$coefficients) == reg.names[iVAR])
pval.seq[iVAR] <- summary(cand.model.lm)$coefficients[iROW,4]
}
enter.idx <- which.min(pval.seq)
if (pval.seq[enter.idx] < alpha.in) {
print(paste("Variable ", reg.names[enter.idx], " enters the model (pval=", sprintf("%6.4f", pval.seq[enter.idx]), ")", sep=""))
} else {
print("No variables enter the model")
enter.idx <- NA
}
} else {
print("No variables available to enter the model")
}
return(enter.idx)
}
backward.step <- function(curr.var.in, alpha.out, resp.name, reg.names, data.name) {
curr.var.in.idx <- which(curr.var.in)
leave.idx <- NA
if (length(curr.var.in.idx) > 0) {
k <- length(reg.names)
pval.seq <- rep(x=-Inf, times=k)
curr.model.str <- get.model.str(curr.var.in, resp.name, reg.names)
curr.model.lm <- eval.lm(curr.model.str, data.name)
for (iVAR in curr.var.in.idx) {
iROW <- which(row.names(summary(curr.model.lm)$coefficients) == reg.names[iVAR])
pval.seq[iVAR] <- summary(curr.model.lm)$coefficients[iROW,4]
}
leave.idx <- which.max(pval.seq)
if (pval.seq[leave.idx] >= alpha.out) {
print(paste("Variable ", reg.names[leave.idx], " leaves the model (pval=", sprintf("%6.4f", pval.seq[leave.idx]), ")", sep=""))
} else {
print("No variables leave the model")
leave.idx <- NA
}
} else {
print("No variables available to leave the model")
}
return(leave.idx)
}
forward.selection <- function(alpha.in, resp.name, reg.names, data.name) {
k <- length(reg.names)
curr.var.in <- rep(x=FALSE, times=k)
stop <- FALSE
while(!stop) {
enter.idx <- forward.step(curr.var.in, alpha.in, resp.name, reg.names, data.name)
if (is.na(enter.idx)) {
stop <- TRUE
} else {
curr.var.in[enter.idx] <- TRUE
}
}
curr.model.str <- get.model.str(curr.var.in, resp.name, reg.names)
print(paste("Final model: ", curr.model.str, sep=""))
curr.model.lm <- eval.lm(curr.model.str, data.name)
return(curr.model.lm)
}
backward.elimination <- function(alpha.out, resp.name, reg.names, data.name) {
k <- length(reg.names)
curr.var.in <- rep(x=TRUE, times=k)
stop <- FALSE
while(!stop) {
leave.idx <- backward.step(curr.var.in, alpha.out, resp.name, reg.names, data.name)
if (is.na(leave.idx)) {
stop <- TRUE
} else {
curr.var.in[leave.idx] <- FALSE
}
}
curr.model.str <- get.model.str(curr.var.in, resp.name, reg.names)
print(paste("Final model: ", curr.model.str, sep=""))
curr.model.lm <- eval.lm(curr.model.str, data.name)
return(curr.model.lm)
}
stepwise.selection <- function(alpha.in, alpha.out, resp.name, reg.names, data.name) {
k <- length(reg.names)
curr.var.in <- rep(x=FALSE, times=k)
stop <- FALSE
while(!stop) {
enter.idx <- forward.step(curr.var.in, alpha.in, resp.name, reg.names, data.name)
if (is.na(enter.idx)) {
stop <- TRUE
} else {
curr.var.in[enter.idx] <- TRUE
leave.idx <- backward.step(curr.var.in, alpha.out, resp.name, reg.names, data.name)
if (!is.na(leave.idx)) {
curr.var.in[leave.idx] <- FALSE
if (leave.idx == enter.idx) {
stop <- TRUE
}
}
}
}
curr.model.str <- get.model.str(curr.var.in, resp.name, reg.names)
print(paste("Final model: ", curr.model.str, sep=""))
curr.model.lm <- eval.lm(curr.model.str, data.name)
return(curr.model.lm)
}
df<-read_csv('data/kc_house_data.csv')
df$year <- format(as.Date(df$date, format="%m/%d/%Y"),"%Y")
df$month <-format(as.Date(df$date, format="%m/%d/%Y"),"%m")
df$price =log(df$price)
df$date = NULL
df$id<-NULL
df$lat<-NULL
df$long<-NULL
df$year<-as.factor(df$year)
df$month<-as.factor(df$month)
df$condition<-as.factor(df$condition)
df$grade<-as.factor(df$grade)
df$yr_renovated<-as.factor(df$yr_renovated)
df$yr_built<-as.factor(df$yr_built)
df$waterfront<-as.factor(df$waterfront)
df$zipcode<-as.factor(df$zipcode)
df$bedrooms<-as.factor(df$bedrooms)
test.lm<-lm(price~.,data=df)
colnames<-colnames(df)
reg.names<-colnames[2:length(colnames)]
reg.names<-c('sqft_living','sqft_basement','sqft_lot','sqft_living15','sqft_lot15')
resp.name<-'price'
data.name <- "df"
alpha.in <- 0.25
alpha.out <- 0.10
df.lm.forward <- forward.selection(alpha.in, resp.name, reg.names, data.name)
df.lm.backward <- backward.elimination(alpha.out, resp.name, reg.names, data.name)
n <- dim(df)[1]
k <- 6
p <- 7
df.vs <- regsubsets(price~ sqft_living + sqft_basement + sqft_living15 + sqft_lot15, data=df, nbest=5)
summary(df.vs)
y.bar <- mean(df$price)
y.cent <- df$price - y.bar
SS.T <- sum(y.cent^2)
y.scl <- y.cent / sqrt(SS.T)
x2.bar <- mean(df$sqft_living)
x2.cent <- df$sqft_living - x2.bar
S.22 <- sum(x2.cent^2)
x2.scl <- x2.cent / sqrt(S.22)
x3.bar <- mean(df$sqft_basement)
x3.cent <- df$sqft_basement- x3.bar
S.33 <- sum(x3.cent^2)
x3.scl <- x3.cent / sqrt(S.33)
x4.bar <- mean(df$sqft_living15)
x4.cent <- df$sqft_living15 - x4.bar
S.44 <- sum(x4.cent^2)
x4.scl <- x4.cent / sqrt(S.44)
x5.bar <- mean(df$sqft_lot15)
x5.cent <- df$sqft_lot15 - x5.bar
S.55 <- sum(x5.cent^2)
x5.scl <- x5.cent / sqrt(S.55)
X.mat.scl <- as.matrix(cbind(x2.scl, x3.scl, x4.scl, x5.scl))
XpX.mat.scl <- t(X.mat.scl) %*% X.mat.scl
Xpy.mat.scl <- t(X.mat.scl) %*% y.scl
eig.out <- eigen(XpX.mat.scl)
eig.val <- eig.out$values
eig.vect <- eig.out$vectors
t=diag(eig.vect)
k=4
#VIF Values.
vif <- rep(x=0, times=k)
for (j in 1:k) {
for (i in 1:k) {
vif[j] <- vif[j] + eig.vect[j,i]^2 / eig.val[i]
}
}
vif
#variance decomposition
var.prop <- matrix(data=0, nrow=k, ncol=k)
for (j in 1:k) {
for (i in 1:k) {
var.prop[i,j] <- (eig.vect[j,i]^2 / eig.val[i]) / vif[j]
}
}
var.prop
single.val <- sqrt(eig.val)
single.val.max <- max(single.val)
cond.idx <- single.val.max / single.val
#conditional indices.
cond.idx
